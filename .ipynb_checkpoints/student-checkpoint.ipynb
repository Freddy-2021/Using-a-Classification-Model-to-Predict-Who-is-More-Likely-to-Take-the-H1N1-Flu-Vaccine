{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![example](images/pexels-pixabay-40568.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 3 Project\n",
    "\n",
    "**Author:** Freddy Abrahamson<br>\n",
    "**Date created:** 3-27-2022<br>\n",
    "**Discipline:** Data Science"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "For this project, I will use multiple linear regression modeling to analyze house sales in King County, in Washington state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Problem\n",
    "\n",
    "The goal of this project is to to provide advice to homeowners about how home renovations can increase the value of their homes, and by what amount. The information for this project is derived from information comprised of the different characteristics of over 20,000 homes in King County,which is located in Washington State. I will use this information gain a better understanding about how different remodels, or renovations to the homes listed, impact their price. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Understanding\n",
    "\n",
    "Describe the data being used for this project.\n",
    "***\n",
    "The data comes from the King County House Sales dataset, in the form of a 'csv' file. The file will be converted into a pandas dataframe. It contains information about the different characteristics of the homes in the King County area,including the number of bedrooms, building grades, square footage, and price. King County is located in Washington State, and has a size of approximately 2300 square miles, per the U.S Census Bureau:\n",
    "\n",
    "kc_house_data.csv\n",
    "\n",
    "\n",
    "I will be giving this dataframe a brief overview of its different characteristics, with a view toward using its columns as variables in a regression model. These include:\n",
    "\n",
    "* dataframe shape: the number of rows and columns in the dataframe\n",
    "* any missing/null values\n",
    "* continuous variables\n",
    "* categorical variables\n",
    "* binary variables\n",
    "* zero inflated variables\n",
    "* outliers\n",
    "\n",
    "Since the goal is to try to gain insights, as to how much much a particular upgrade or remodel can the impact the\n",
    "price of the house, as opposed to predicting home prices, I will be placing an emphasis on choosing features with the least explanatory overlap. To that end, for instance, I would favor a feature such as a bedroom, or a bathroom over square footage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "#warnings.filterwarnings('ignore')\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing dataset\n",
    "df = pd.read_csv('H1N1_Flu_Vaccines.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 26707 entries, 0 to 26706\n",
      "Data columns (total 38 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   respondent_id                26707 non-null  int64  \n",
      " 1   h1n1_concern                 26615 non-null  float64\n",
      " 2   h1n1_knowledge               26591 non-null  float64\n",
      " 3   behavioral_antiviral_meds    26636 non-null  float64\n",
      " 4   behavioral_avoidance         26499 non-null  float64\n",
      " 5   behavioral_face_mask         26688 non-null  float64\n",
      " 6   behavioral_wash_hands        26665 non-null  float64\n",
      " 7   behavioral_large_gatherings  26620 non-null  float64\n",
      " 8   behavioral_outside_home      26625 non-null  float64\n",
      " 9   behavioral_touch_face        26579 non-null  float64\n",
      " 10  doctor_recc_h1n1             24547 non-null  float64\n",
      " 11  doctor_recc_seasonal         24547 non-null  float64\n",
      " 12  chronic_med_condition        25736 non-null  float64\n",
      " 13  child_under_6_months         25887 non-null  float64\n",
      " 14  health_worker                25903 non-null  float64\n",
      " 15  health_insurance             14433 non-null  float64\n",
      " 16  opinion_h1n1_vacc_effective  26316 non-null  float64\n",
      " 17  opinion_h1n1_risk            26319 non-null  float64\n",
      " 18  opinion_h1n1_sick_from_vacc  26312 non-null  float64\n",
      " 19  opinion_seas_vacc_effective  26245 non-null  float64\n",
      " 20  opinion_seas_risk            26193 non-null  float64\n",
      " 21  opinion_seas_sick_from_vacc  26170 non-null  float64\n",
      " 22  age_group                    26707 non-null  object \n",
      " 23  education                    25300 non-null  object \n",
      " 24  race                         26707 non-null  object \n",
      " 25  sex                          26707 non-null  object \n",
      " 26  income_poverty               22284 non-null  object \n",
      " 27  marital_status               25299 non-null  object \n",
      " 28  rent_or_own                  24665 non-null  object \n",
      " 29  employment_status            25244 non-null  object \n",
      " 30  hhs_geo_region               26707 non-null  object \n",
      " 31  census_msa                   26707 non-null  object \n",
      " 32  household_adults             26458 non-null  float64\n",
      " 33  household_children           26458 non-null  float64\n",
      " 34  employment_industry          13377 non-null  object \n",
      " 35  employment_occupation        13237 non-null  object \n",
      " 36  h1n1_vaccine                 26707 non-null  int64  \n",
      " 37  seasonal_vaccine             26707 non-null  int64  \n",
      "dtypes: float64(23), int64(3), object(12)\n",
      "memory usage: 7.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>respondent_id</th>\n",
       "      <th>h1n1_concern</th>\n",
       "      <th>h1n1_knowledge</th>\n",
       "      <th>behavioral_antiviral_meds</th>\n",
       "      <th>behavioral_avoidance</th>\n",
       "      <th>behavioral_face_mask</th>\n",
       "      <th>behavioral_wash_hands</th>\n",
       "      <th>behavioral_large_gatherings</th>\n",
       "      <th>behavioral_outside_home</th>\n",
       "      <th>behavioral_touch_face</th>\n",
       "      <th>...</th>\n",
       "      <th>rent_or_own</th>\n",
       "      <th>employment_status</th>\n",
       "      <th>hhs_geo_region</th>\n",
       "      <th>census_msa</th>\n",
       "      <th>household_adults</th>\n",
       "      <th>household_children</th>\n",
       "      <th>employment_industry</th>\n",
       "      <th>employment_occupation</th>\n",
       "      <th>h1n1_vaccine</th>\n",
       "      <th>seasonal_vaccine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Own</td>\n",
       "      <td>Not in Labor Force</td>\n",
       "      <td>oxchjgsf</td>\n",
       "      <td>Non-MSA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Rent</td>\n",
       "      <td>Employed</td>\n",
       "      <td>bhuqouqj</td>\n",
       "      <td>MSA, Not Principle  City</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>pxcmvdjn</td>\n",
       "      <td>xgwztkwe</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Own</td>\n",
       "      <td>Employed</td>\n",
       "      <td>qufhixun</td>\n",
       "      <td>MSA, Not Principle  City</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>rucpziij</td>\n",
       "      <td>xtkaffoo</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Rent</td>\n",
       "      <td>Not in Labor Force</td>\n",
       "      <td>lrircsnp</td>\n",
       "      <td>MSA, Principle City</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Own</td>\n",
       "      <td>Employed</td>\n",
       "      <td>qufhixun</td>\n",
       "      <td>MSA, Not Principle  City</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>wxleyezf</td>\n",
       "      <td>emcorrxb</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   respondent_id  h1n1_concern  h1n1_knowledge  behavioral_antiviral_meds  \\\n",
       "0              0           1.0             0.0                        0.0   \n",
       "1              1           3.0             2.0                        0.0   \n",
       "2              2           1.0             1.0                        0.0   \n",
       "3              3           1.0             1.0                        0.0   \n",
       "4              4           2.0             1.0                        0.0   \n",
       "\n",
       "   behavioral_avoidance  behavioral_face_mask  behavioral_wash_hands  \\\n",
       "0                   0.0                   0.0                    0.0   \n",
       "1                   1.0                   0.0                    1.0   \n",
       "2                   1.0                   0.0                    0.0   \n",
       "3                   1.0                   0.0                    1.0   \n",
       "4                   1.0                   0.0                    1.0   \n",
       "\n",
       "   behavioral_large_gatherings  behavioral_outside_home  \\\n",
       "0                          0.0                      1.0   \n",
       "1                          0.0                      1.0   \n",
       "2                          0.0                      0.0   \n",
       "3                          1.0                      0.0   \n",
       "4                          1.0                      0.0   \n",
       "\n",
       "   behavioral_touch_face  ...  rent_or_own   employment_status  \\\n",
       "0                    1.0  ...          Own  Not in Labor Force   \n",
       "1                    1.0  ...         Rent            Employed   \n",
       "2                    0.0  ...          Own            Employed   \n",
       "3                    0.0  ...         Rent  Not in Labor Force   \n",
       "4                    1.0  ...          Own            Employed   \n",
       "\n",
       "   hhs_geo_region                census_msa  household_adults  \\\n",
       "0        oxchjgsf                   Non-MSA               0.0   \n",
       "1        bhuqouqj  MSA, Not Principle  City               0.0   \n",
       "2        qufhixun  MSA, Not Principle  City               2.0   \n",
       "3        lrircsnp       MSA, Principle City               0.0   \n",
       "4        qufhixun  MSA, Not Principle  City               1.0   \n",
       "\n",
       "   household_children  employment_industry  employment_occupation  \\\n",
       "0                 0.0                  NaN                    NaN   \n",
       "1                 0.0             pxcmvdjn               xgwztkwe   \n",
       "2                 0.0             rucpziij               xtkaffoo   \n",
       "3                 0.0                  NaN                    NaN   \n",
       "4                 0.0             wxleyezf               emcorrxb   \n",
       "\n",
       "   h1n1_vaccine  seasonal_vaccine  \n",
       "0             0                 0  \n",
       "1             0                 1  \n",
       "2             0                 0  \n",
       "3             0                 1  \n",
       "4             0                 0  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Counts\n",
      "0    21033\n",
      "1     5674\n",
      "Name: h1n1_vaccine, dtype: int64\n",
      "\n",
      "Percentages\n",
      "0    0.787546\n",
      "1    0.212454\n",
      "Name: h1n1_vaccine, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Raw Counts\")\n",
    "print(df[\"h1n1_vaccine\"].value_counts())\n",
    "print()\n",
    "print(\"Percentages\")\n",
    "print(df[\"h1n1_vaccine\"].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>A baseline model that always chose the majority class would have an accuracy of over 78%.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing the Data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping Features, Train-test-split, and Dealing with Missing Values: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#I will drop:\n",
    "# 'respondent_id' - since it is a unique identifier\n",
    "# 'employment_industry','employment_occupation','health_insurance' - about 50% or more records missing \n",
    "# 'seasonal_vaccine' - we will not account for this classification\n",
    "df_II = df.drop(['respondent_id','seasonal_vaccine','employment_industry','employment_occupation','health_insurance' ], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split df into X and y\n",
    "X = df_II.drop(\"h1n1_vaccine\", axis=1)\n",
    "y = df_II[\"h1n1_vaccine\"]\n",
    "\n",
    "# Perform train-test split with random_state=42 and stratify=y\n",
    "# stratify y to maintain uniform ratios of dependent variable y\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#impute values based on most common value in each column:\n",
    "X_train = X_train.apply(lambda x:x.fillna(x.value_counts().index[0]))\n",
    "X_test = X_test.apply(lambda x:x.fillna(x.value_counts().index[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>There is now no missing data in the training dataset.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>h1n1_concern_0.0</th>\n",
       "      <th>h1n1_concern_1.0</th>\n",
       "      <th>h1n1_concern_2.0</th>\n",
       "      <th>h1n1_concern_3.0</th>\n",
       "      <th>h1n1_knowledge_0.0</th>\n",
       "      <th>h1n1_knowledge_1.0</th>\n",
       "      <th>h1n1_knowledge_2.0</th>\n",
       "      <th>behavioral_antiviral_meds_0.0</th>\n",
       "      <th>behavioral_antiviral_meds_1.0</th>\n",
       "      <th>behavioral_avoidance_0.0</th>\n",
       "      <th>...</th>\n",
       "      <th>census_msa_MSA, Principle City</th>\n",
       "      <th>census_msa_Non-MSA</th>\n",
       "      <th>household_adults_0.0</th>\n",
       "      <th>household_adults_1.0</th>\n",
       "      <th>household_adults_2.0</th>\n",
       "      <th>household_adults_3.0</th>\n",
       "      <th>household_children_0.0</th>\n",
       "      <th>household_children_1.0</th>\n",
       "      <th>household_children_2.0</th>\n",
       "      <th>household_children_3.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 107 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   h1n1_concern_0.0  h1n1_concern_1.0  h1n1_concern_2.0  h1n1_concern_3.0  \\\n",
       "0               0.0               0.0               1.0               0.0   \n",
       "1               0.0               0.0               0.0               1.0   \n",
       "2               0.0               0.0               1.0               0.0   \n",
       "3               0.0               0.0               1.0               0.0   \n",
       "4               0.0               0.0               0.0               1.0   \n",
       "\n",
       "   h1n1_knowledge_0.0  h1n1_knowledge_1.0  h1n1_knowledge_2.0  \\\n",
       "0                 0.0                 0.0                 1.0   \n",
       "1                 0.0                 0.0                 1.0   \n",
       "2                 0.0                 1.0                 0.0   \n",
       "3                 0.0                 1.0                 0.0   \n",
       "4                 0.0                 0.0                 1.0   \n",
       "\n",
       "   behavioral_antiviral_meds_0.0  behavioral_antiviral_meds_1.0  \\\n",
       "0                            1.0                            0.0   \n",
       "1                            1.0                            0.0   \n",
       "2                            1.0                            0.0   \n",
       "3                            0.0                            1.0   \n",
       "4                            1.0                            0.0   \n",
       "\n",
       "   behavioral_avoidance_0.0  ...  census_msa_MSA, Principle City  \\\n",
       "0                       0.0  ...                             0.0   \n",
       "1                       0.0  ...                             1.0   \n",
       "2                       1.0  ...                             0.0   \n",
       "3                       0.0  ...                             0.0   \n",
       "4                       1.0  ...                             0.0   \n",
       "\n",
       "   census_msa_Non-MSA  household_adults_0.0  household_adults_1.0  \\\n",
       "0                 0.0                   0.0                   1.0   \n",
       "1                 0.0                   0.0                   1.0   \n",
       "2                 1.0                   0.0                   1.0   \n",
       "3                 1.0                   1.0                   0.0   \n",
       "4                 0.0                   0.0                   1.0   \n",
       "\n",
       "   household_adults_2.0  household_adults_3.0  household_children_0.0  \\\n",
       "0                   0.0                   0.0                     0.0   \n",
       "1                   0.0                   0.0                     1.0   \n",
       "2                   0.0                   0.0                     1.0   \n",
       "3                   0.0                   0.0                     1.0   \n",
       "4                   0.0                   0.0                     1.0   \n",
       "\n",
       "   household_children_1.0  household_children_2.0  household_children_3.0  \n",
       "0                     0.0                     1.0                     0.0  \n",
       "1                     0.0                     0.0                     0.0  \n",
       "2                     0.0                     0.0                     0.0  \n",
       "3                     0.0                     0.0                     0.0  \n",
       "4                     0.0                     0.0                     0.0  \n",
       "\n",
       "[5 rows x 107 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I will convert all the columns in the dataset to string type, so I can then one-hot encode them:\n",
    "X_train_II = X_train.astype(str)\n",
    "\n",
    "# creating a OneHotEncoder object:\n",
    "ohe = OneHotEncoder(categories=\"auto\", handle_unknown=\"ignore\", sparse=False)\n",
    "\n",
    "# fitting dataset to OneHotEncoder object:\n",
    "ohe.fit(X_train_II)\n",
    "\n",
    "# creating an array with ohe column names:\n",
    "col_names = ohe.get_feature_names(X_train_II.columns)\n",
    "\n",
    "# Create transformed dataframe\n",
    "X_train_II_encoded = pd.DataFrame(ohe.fit_transform(X_train_II), columns=col_names)\n",
    "X_train_II_encoded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will convert all the columns in the dataset to string type, so I can then one-hot encode them:\n",
    "X_test_II = X_test.astype(str)\n",
    "\n",
    "# Create transformed dataframe. No need to fit. Use same column names array:\n",
    "X_test_II_encoded = pd.DataFrame(ohe.transform(X_test_II), columns=col_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification models:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Nearest Neighbors (KNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K Nearest Neighbors Baseline Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Cross Validation Score: 80.55%\n"
     ]
    }
   ],
   "source": [
    "# Creating K nearest neighbor classifier object \n",
    "knn = KNeighborsClassifier(n_jobs = -1)\n",
    "\n",
    "# using 2-split cross-validation to score the classification:\n",
    "knn_cv_score = cross_val_score(knn, X_train_II_encoded, y_train, cv=2)\n",
    "\n",
    "# return the mean of the 5 accuracy scores:\n",
    "mean_knn_cv_score = np.mean(knn_cv_score)\n",
    "print(f\"Mean Cross Validation Score: {mean_knn_cv_score :.2%}\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The model did significantly better than we would expect from random guessing (~60% better),\n",
    "and slightly better than we would expect if we simply choose the majority label (~79%)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using GridSearchCV to create additional KNN models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid:\n",
    "\n",
    "knn_param_grid = {\n",
    "    'n_neighbors': [5,12,20],\n",
    "    'metric'     : ['minkowski'],\n",
    "    'p'          : [1,2,3,4]\n",
    "}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Note: I was unable to add more options to the grid (n_neighbors, distance metric, weights) because it takes \n",
    "too long to fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, estimator=KNeighborsClassifier(n_jobs=-1), n_jobs=-1,\n",
       "             param_grid={'metric': ['minkowski'], 'n_neighbors': [5, 12, 20],\n",
       "                         'p': [1, 2, 3, 4]},\n",
       "             return_train_score=True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate GridSearchCV object:\n",
    "knn_grid_search = GridSearchCV(knn, knn_param_grid, cv=2, return_train_score=True, n_jobs = -1)\n",
    "\n",
    "# Fit to the data\n",
    "knn_grid_search.fit(X_train_II_encoded, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Training Score: 83.93%\n",
      "Mean Test Score: 81.37%\n",
      "Best Parameter Combination (to return highest score for the holdout data):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'metric': 'minkowski', 'n_neighbors': 20, 'p': 1}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean training score\n",
    "knn_gs_training_score = np.mean(knn_grid_search.cv_results_['mean_train_score'])\n",
    "\n",
    "# Mean test score\n",
    "knn_grid_search.score(X_test_II_encoded, y_test)\n",
    "knn_gs_testing_score = np.mean(knn_grid_search.cv_results_['mean_test_score'])\n",
    "\n",
    "print(f\"Mean Training Score: {knn_gs_training_score :.2%}\")\n",
    "print(f\"Mean Test Score: {knn_gs_testing_score :.2%}\")\n",
    "print(\"Best Parameter Combination (to return highest score for the holdout data):\")\n",
    "knn_grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>score_dif</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.839308</td>\n",
       "      <td>0.813663</td>\n",
       "      <td>0.025645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.011144</td>\n",
       "      <td>0.006086</td>\n",
       "      <td>0.017222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.829406</td>\n",
       "      <td>0.805492</td>\n",
       "      <td>0.010734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.829406</td>\n",
       "      <td>0.805492</td>\n",
       "      <td>0.010734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.834398</td>\n",
       "      <td>0.816825</td>\n",
       "      <td>0.017574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.854119</td>\n",
       "      <td>0.818672</td>\n",
       "      <td>0.048627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.854119</td>\n",
       "      <td>0.818672</td>\n",
       "      <td>0.048627</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       mean_train_score  mean_test_score  score_dif\n",
       "count         12.000000        12.000000  12.000000\n",
       "mean           0.839308         0.813663   0.025645\n",
       "std            0.011144         0.006086   0.017222\n",
       "min            0.829406         0.805492   0.010734\n",
       "25%            0.829406         0.805492   0.010734\n",
       "50%            0.834398         0.816825   0.017574\n",
       "75%            0.854119         0.818672   0.048627\n",
       "max            0.854119         0.818672   0.048627"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creates a dataframe from knn_grid_search.cv_results_ dictionary:\n",
    "knn_cv_grid_df = pd.DataFrame(knn_grid_search.cv_results_)\n",
    "\n",
    "# adding new column \n",
    "knn_cv_grid_df['score_dif'] = abs(knn_cv_grid_df['mean_train_score'] - knn_cv_grid_df['mean_test_score'])\n",
    "\n",
    "# creates new dataframe with only 'train' and 'test' scores\n",
    "knn_scores = knn_cv_grid_df.loc[:,['mean_train_score','mean_test_score','score_dif']]\n",
    "knn_scores.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Baseline Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Cross Validation Score: 75.02%\n"
     ]
    }
   ],
   "source": [
    "# Creating decision tree classifier object\n",
    "dec_tree = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# using 2-split cross-validation to score the classification:\n",
    "dec_tree_cv_score = cross_val_score(dec_tree, X_train_II_encoded, y_train, cv=2)\n",
    "\n",
    "# return the mean of the 2 accuracy scores:\n",
    "mean_dec_tree_cv_score = np.mean(dec_tree_cv_score)\n",
    "print(f\"Mean Cross Validation Score: {mean_dec_tree_cv_score :.2%}\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The model did significantly better than we would expect from random guessing (~50% better),\n",
    "but slightly worse than we would expect if we simply choose the majority label (~79%)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using GridSearchCV to create additional Decision Tree models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00014796956808722217"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = dec_tree.cost_complexity_pruning_path(X_train_II_encoded, y_train)\n",
    "ccp_alphas, impurities = path.ccp_alphas, path.impurities\n",
    "ccp_alphas.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid:\n",
    "\n",
    "dec_tree_param_grid = {\n",
    "    'criterion'        : ['gini', 'entropy'],\n",
    "    'max_depth'        : [None, 7, 8],\n",
    "    'min_samples_split': [2,3,5],\n",
    "    'min_samples_leaf' : [1, 2, 3, 4, 5, 6],\n",
    "    'class_weight'     : [None, 'balanced']\n",
    "    #'ccp_alpha'        : [None, 0.00014796956808722217]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, estimator=DecisionTreeClassifier(random_state=42), n_jobs=-1,\n",
       "             param_grid={'class_weight': [None, 'balanced'],\n",
       "                         'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': [None, 7, 8],\n",
       "                         'min_samples_leaf': [1, 2, 3, 4, 5, 6],\n",
       "                         'min_samples_split': [2, 3, 5]},\n",
       "             return_train_score=True)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate GridSearchCV object:\n",
    "dec_tree_grid_search = GridSearchCV(dec_tree, dec_tree_param_grid, cv=2, return_train_score=True, \n",
    "                                    n_jobs = -1)\n",
    "\n",
    "# Fit to the data\n",
    "dec_tree_grid_search.fit(X_train_II_encoded, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Training Score: 85.61%\n",
      "Mean Test Score: 78.14%\n",
      "Best Parameter Combination (to return highest score for the holdout data):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'class_weight': None,\n",
       " 'criterion': 'entropy',\n",
       " 'max_depth': 7,\n",
       " 'min_samples_leaf': 5,\n",
       " 'min_samples_split': 2}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean training score\n",
    "dec_tree_gs_training_score = np.mean(dec_tree_grid_search.cv_results_['mean_train_score'])\n",
    "\n",
    "# Mean test score\n",
    "dec_tree_grid_search.score(X_test_II_encoded, y_test)\n",
    "dec_tree_gs_testing_score = np.mean(dec_tree_grid_search.cv_results_['mean_test_score'])\n",
    "\n",
    "# Print Results\n",
    "print(f\"Mean Training Score: {dec_tree_gs_training_score :.2%}\")\n",
    "print(f\"Mean Test Score: {dec_tree_gs_testing_score :.2%}\")\n",
    "print(\"Best Parameter Combination (to return highest score for the holdout data):\")\n",
    "dec_tree_grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>score_dif</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>216.000000</td>\n",
       "      <td>216.000000</td>\n",
       "      <td>216.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.856119</td>\n",
       "      <td>0.781356</td>\n",
       "      <td>0.074763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.056444</td>\n",
       "      <td>0.032498</td>\n",
       "      <td>0.069446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.789166</td>\n",
       "      <td>0.719321</td>\n",
       "      <td>0.019571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.802197</td>\n",
       "      <td>0.763854</td>\n",
       "      <td>0.026710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.850924</td>\n",
       "      <td>0.770944</td>\n",
       "      <td>0.033849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.885721</td>\n",
       "      <td>0.818884</td>\n",
       "      <td>0.127172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.825761</td>\n",
       "      <td>0.249825</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       mean_train_score  mean_test_score   score_dif\n",
       "count        216.000000       216.000000  216.000000\n",
       "mean           0.856119         0.781356    0.074763\n",
       "std            0.056444         0.032498    0.069446\n",
       "min            0.789166         0.719321    0.019571\n",
       "25%            0.802197         0.763854    0.026710\n",
       "50%            0.850924         0.770944    0.033849\n",
       "75%            0.885721         0.818884    0.127172\n",
       "max            1.000000         0.825761    0.249825"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creates a dataframe from dec_tree_grid_search.cv_results_ dictionary:\n",
    "dec_tree_gs_df = pd.DataFrame(dec_tree_grid_search.cv_results_)\n",
    "\n",
    "# adding new column:\n",
    "dec_tree_gs_df['score_dif'] = abs(dec_tree_gs_df['mean_train_score'] -  dec_tree_gs_df['mean_test_score'])\n",
    "\n",
    "# creates new dataframe with only 'train','test' scores, and their difference:\n",
    "dec_tree_scores = dec_tree_gs_df.loc[:,['mean_train_score','mean_test_score','score_dif']]\n",
    "dec_tree_scores.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Baseline Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Cross Validation Score: 83.31%\n"
     ]
    }
   ],
   "source": [
    "# Creating random forest classifier object\n",
    "forest = RandomForestClassifier(n_jobs = -1,random_state=42)\n",
    "\n",
    "# using 5-split cross-validation to score the classification:\n",
    "forest_cv_score = cross_val_score(forest, X_train_II_encoded, y_train, cv=2)\n",
    "\n",
    "# return the mean of the 5 accuracy scores:\n",
    "mean_forest_cv_score = np.mean(forest_cv_score)\n",
    "print(f\"Mean Cross Validation Score: {mean_forest_cv_score :.2%}\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The model did significantly better than we would expect from random guessing (~66% better),\n",
    "but slightly worse than we would expect if we simply choose the majority label (~79%)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using GridSearchCV to create additional Random Forests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid:\n",
    "\n",
    "forest_param_grid = {\n",
    "              'criterion'        : ['gini', 'entropy'],\n",
    "              'max_depth'        : [None, 4, 6,8],\n",
    "              'min_samples_split': [2,3,4,6],\n",
    "              'max_features'     : [15, 54,'auto'],\n",
    "             'class_weight'      : [None, 'balanced'],\n",
    "              'n_estimators'     : [100, 140]\n",
    "         \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, estimator=RandomForestClassifier(n_jobs=-1, random_state=42),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'class_weight': [None, 'balanced'],\n",
       "                         'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': [None, 4, 6, 8],\n",
       "                         'max_features': [15, 54, 'auto'],\n",
       "                         'min_samples_split': [2, 3, 4, 6],\n",
       "                         'n_estimators': [100, 140]},\n",
       "             return_train_score=True)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate GridSearchCV object:\n",
    "forest_grid_search = GridSearchCV(forest, forest_param_grid, cv=2, return_train_score=True,\n",
    "                                  n_jobs = -1)\n",
    "\n",
    "# Fit to the data\n",
    "forest_grid_search.fit(X_train_II_encoded, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Training Score: 86.48%\n",
      "Mean Test Score: 81.32%\n",
      "Best Parameter Combination (to return highest score for the holdout data):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'min_samples_split': 4,\n",
       " 'n_estimators': 100}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean training score\n",
    "forest_gs_training_score = np.mean(forest_grid_search.cv_results_['mean_train_score'])\n",
    "\n",
    "# Mean test score\n",
    "forest_grid_search.score(X_test_II_encoded, y_test)\n",
    "forest_gs_testing_score = np.mean(forest_grid_search.cv_results_['mean_test_score'])\n",
    "\n",
    "print(f\"Mean Training Score: {forest_gs_training_score :.2%}\")\n",
    "print(f\"Mean Test Score: {forest_gs_testing_score :.2%}\")\n",
    "print(\"Best Parameter Combination (to return highest score for the holdout data):\")\n",
    "forest_grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>score_dif</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>384.000000</td>\n",
       "      <td>384.000000</td>\n",
       "      <td>384.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.864814</td>\n",
       "      <td>0.813245</td>\n",
       "      <td>0.051569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.077370</td>\n",
       "      <td>0.021527</td>\n",
       "      <td>0.063759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.767149</td>\n",
       "      <td>0.763804</td>\n",
       "      <td>0.002896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.813692</td>\n",
       "      <td>0.794284</td>\n",
       "      <td>0.008050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.834199</td>\n",
       "      <td>0.825487</td>\n",
       "      <td>0.017773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.894121</td>\n",
       "      <td>0.831503</td>\n",
       "      <td>0.061533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.835247</td>\n",
       "      <td>0.171842</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       mean_train_score  mean_test_score   score_dif\n",
       "count        384.000000       384.000000  384.000000\n",
       "mean           0.864814         0.813245    0.051569\n",
       "std            0.077370         0.021527    0.063759\n",
       "min            0.767149         0.763804    0.002896\n",
       "25%            0.813692         0.794284    0.008050\n",
       "50%            0.834199         0.825487    0.017773\n",
       "75%            0.894121         0.831503    0.061533\n",
       "max            1.000000         0.835247    0.171842"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creates a dataframe from forest_grid_search.cv_results_ dictionary:\n",
    "forest_cv_grid_df = pd.DataFrame(forest_grid_search.cv_results_)\n",
    "\n",
    "# adding new column:\n",
    "forest_cv_grid_df['score_dif'] = abs(forest_cv_grid_df['mean_train_score'] - forest_cv_grid_df['mean_test_score'])\n",
    "\n",
    "# creates new dataframe with only 'train','test' scores, and their difference:\n",
    "forest_scores = forest_cv_grid_df.loc[:,['mean_train_score','mean_test_score','score_dif']]\n",
    "forest_scores.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_III_encoded = X_train_II_encoded.rename(columns={'education_< 12 Years': 'education less than 12 Years', \n",
    "                                                         'income_poverty_<= $75,000, Above Poverty':\n",
    "                                                         'income_poverty less than or = to $75000_Above Poverty'})\n",
    "X_test_III_encoded = X_test_II_encoded.rename(columns={'education_< 12 Years': 'education less than 12 Years', \n",
    "                                                         'income_poverty_<= $75,000, Above Poverty':\n",
    "                                                         'income_poverty less than or = to $75000_Above Poverty'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost Baseline Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Cross Validation Score: 82.27%\n"
     ]
    }
   ],
   "source": [
    "# Creating random forest classifier object\n",
    "xgboost_clf = XGBClassifier(random_state=42, n_jobs = -1)\n",
    "\n",
    "# using 2-split cross-validation to score the classification:\n",
    "xgboost_clf_cv_score = cross_val_score(xgboost_clf, X_train_III_encoded, y_train, cv=2)\n",
    "\n",
    "# return the mean of the 2 accuracy scores:\n",
    "mean_xgboost_clf_cv_score = np.mean(xgboost_clf_cv_score)\n",
    "print(f\"Mean Cross Validation Score: {mean_xgboost_clf_cv_score :.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using GridSearchCV to create additional XGBoost Classifiers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Define the parameter grid:\n",
    "\n",
    "xgboost_param_grid = {\n",
    "    'learning_rate': [None, .08, 0.09],\n",
    "    'max_depth': [None, 4, 5],\n",
    "    'min_child_weight': [1, 2, 3],\n",
    "    'subsample': [0.65, 1],\n",
    "    'min_split_loss' : [0, .5],\n",
    "    'n_estimators' : [100, 160],\n",
    "    'reg_alpha':[None, .5,]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, gamma=None,\n",
       "                                     gpu_id=None, importance_type='gain',\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_delta_step=None,\n",
       "                                     max_depth=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs...\n",
       "                                     reg_alpha=None, reg_lambda=None,\n",
       "                                     scale_pos_weight=None, subsample=None,\n",
       "                                     tree_method=None, validate_parameters=None,\n",
       "                                     verbosity=None),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'learning_rate': [None, 0.08, 0.09],\n",
       "                         'max_depth': [None, 4, 5],\n",
       "                         'min_child_weight': [1, 2, 3],\n",
       "                         'min_split_loss': [0, 0.5], 'n_estimators': [100, 160],\n",
       "                         'reg_alpha': [None, 0.5], 'subsample': [0.65, 1]},\n",
       "             return_train_score=True)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate GridSearchCV object:\n",
    "xgboost_clf_grid_search = GridSearchCV(xgboost_clf, xgboost_param_grid, cv=2, return_train_score=True,\n",
    "                                  n_jobs = -1)\n",
    "\n",
    "# Fit to the data\n",
    "xgboost_clf_grid_search.fit(X_train_III_encoded, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Training Score: 89.39%\n",
      "Mean Test Score: 83.25%\n",
      "Best Parameter Combination (to return highest score for the holdout data):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.08,\n",
       " 'max_depth': 4,\n",
       " 'min_child_weight': 2,\n",
       " 'min_split_loss': 0,\n",
       " 'n_estimators': 160,\n",
       " 'reg_alpha': 0.5,\n",
       " 'subsample': 1}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean training score\n",
    "xgboost_clf_gs_training_score = np.mean(xgboost_clf_grid_search.cv_results_['mean_train_score'])\n",
    "\n",
    "# Mean test score\n",
    "xgboost_clf_grid_search.score(X_test_III_encoded, y_test)\n",
    "xgboost_clf_gs_testing_score = np.mean(xgboost_clf_grid_search.cv_results_['mean_test_score'])\n",
    "\n",
    "print(f\"Mean Training Score: {xgboost_clf_gs_training_score :.2%}\")\n",
    "print(f\"Mean Test Score: {xgboost_clf_gs_testing_score :.2%}\")\n",
    "print(\"Best Parameter Combination (to return highest score for the holdout data):\")\n",
    "xgboost_clf_grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>score_dif</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>432.000000</td>\n",
       "      <td>432.000000</td>\n",
       "      <td>432.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.893937</td>\n",
       "      <td>0.832498</td>\n",
       "      <td>0.061439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.033130</td>\n",
       "      <td>0.006507</td>\n",
       "      <td>0.039118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.853669</td>\n",
       "      <td>0.812831</td>\n",
       "      <td>0.015726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.867212</td>\n",
       "      <td>0.827758</td>\n",
       "      <td>0.029331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.884548</td>\n",
       "      <td>0.835597</td>\n",
       "      <td>0.050275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.908150</td>\n",
       "      <td>0.837444</td>\n",
       "      <td>0.077634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.983475</td>\n",
       "      <td>0.839491</td>\n",
       "      <td>0.168797</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       mean_train_score  mean_test_score   score_dif\n",
       "count        432.000000       432.000000  432.000000\n",
       "mean           0.893937         0.832498    0.061439\n",
       "std            0.033130         0.006507    0.039118\n",
       "min            0.853669         0.812831    0.015726\n",
       "25%            0.867212         0.827758    0.029331\n",
       "50%            0.884548         0.835597    0.050275\n",
       "75%            0.908150         0.837444    0.077634\n",
       "max            0.983475         0.839491    0.168797"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creates a dataframe from xgboost_clf_grid_search.cv_results_ dictionary:\n",
    "xgboost_clf_grid_df = pd.DataFrame(xgboost_clf_grid_search.cv_results_)\n",
    "\n",
    "# adding new column:\n",
    "xgboost_clf_grid_df['score_dif'] = abs(xgboost_clf_grid_df['mean_train_score'] - \n",
    "                                       xgboost_clf_grid_df['mean_test_score'])\n",
    "\n",
    "# creates new dataframe with only 'train','test' scores, and their difference:\n",
    "xgboost_scores = xgboost_clf_grid_df.loc[:,['mean_train_score','mean_test_score','score_dif']]\n",
    "xgboost_scores.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
