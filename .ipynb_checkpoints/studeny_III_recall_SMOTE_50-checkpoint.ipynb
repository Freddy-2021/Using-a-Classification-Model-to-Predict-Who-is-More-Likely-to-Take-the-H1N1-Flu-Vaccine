{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![example](images/pexels-pixabay-40568.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 3 Project\n",
    "\n",
    "**Author:** Freddy Abrahamson<br>\n",
    "**Date created:** 3-27-2022<br>\n",
    "**Discipline:** Data Science"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "For this project, I will use multiple linear regression modeling to analyze house sales in King County, in Washington state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Problem\n",
    "\n",
    "The goal of this project is to to provide advice to homeowners about how home renovations can increase the value of their homes, and by what amount. The information for this project is derived from information comprised of the different characteristics of over 20,000 homes in King County,which is located in Washington State. I will use this information gain a better understanding about how different remodels, or renovations to the homes listed, impact their price. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Understanding\n",
    "\n",
    "Describe the data being used for this project.\n",
    "***\n",
    "The data comes from the King County House Sales dataset, in the form of a 'csv' file. The file will be converted into a pandas dataframe. It contains information about the different characteristics of the homes in the King County area,including the number of bedrooms, building grades, square footage, and price. King County is located in Washington State, and has a size of approximately 2300 square miles, per the U.S Census Bureau:\n",
    "\n",
    "kc_house_data.csv\n",
    "\n",
    "\n",
    "I will be giving this dataframe a brief overview of its different characteristics, with a view toward using its columns as variables in a regression model. These include:\n",
    "\n",
    "* dataframe shape: the number of rows and columns in the dataframe\n",
    "* any missing/null values\n",
    "* continuous variables\n",
    "* categorical variables\n",
    "* binary variables\n",
    "* zero inflated variables\n",
    "* outliers\n",
    "\n",
    "Since the goal is to try to gain insights, as to how much much a particular upgrade or remodel can the impact the\n",
    "price of the house, as opposed to predicting home prices, I will be placing an emphasis on choosing features with the least explanatory overlap. To that end, for instance, I would favor a feature such as a bedroom, or a bathroom over square footage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "#warnings.filterwarnings('ignore')\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, VotingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from sklearn.metrics import (accuracy_score, confusion_matrix, roc_curve, auc, roc_auc_score,f1_score,\n",
    "                             classification_report, plot_confusion_matrix, precision_recall_curve,\n",
    "                             recall_score)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import shap\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best_model function returns the best train test score combination based on the auc function, where\n",
    "the difference between the test and the train scores represents the x axis, and test score represents\n",
    "the y axis. In order use the auc function, for each x,y coordinate we created a list of length three,\n",
    "with 0 and 1 at the ends, and the actual x,y values in the middle.\n",
    "\n",
    "The function takes as arguments(data derived from 'cv_results_' form gridsearch):\n",
    "1. The type of model used. Will be returned as a string.\n",
    "2. df1: The dataframe where the 'mean test scores' column, and the column containing the \n",
    "   difference between the train and test scores are located.\n",
    "3. df2: The dataframe with the column cointiaining the model parameters(possibly the same). \n",
    "\n",
    "The function returns the following:\n",
    "1. model type: returned as a string\n",
    "2. best test score: the test score that corresponds to the best auc score\n",
    "3. best score difference: the difference between the train and test scores\n",
    "   that corresponds to the best auc score\n",
    "4. best train-test combination score(auc): the greatest auc score using the \n",
    "   'score difference' as the x values, and the 'test score' as the y values\n",
    "5. best parameters: the model parameters that correspond to the best auc score\n",
    "6. best dataframe row: the dataframe row in which the best auc score is found\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_model(model_type, df1, df2):\n",
    "    from sklearn.metrics import auc\n",
    "    \n",
    "\n",
    "#   creating 'test_scores' and 'score_diffs' zero populated lists of shape(rows,3) \n",
    "    rows = len(df1)\n",
    "    test_scores = np.zeros((rows, 3))\n",
    "    score_diffs = np.zeros((rows, 3))\n",
    "    auc_scores = []\n",
    "\n",
    "#   populating 'test_scores' and 'score_diffs' so each list has a format [0,test_score,1],\n",
    "#   and [0,score_diff,1] respectively\n",
    "    for row in range(rows):\n",
    "        test_scores[row][1] = df1['mean_test_score'][row]\n",
    "        test_scores[row][2] = 1\n",
    "        score_diffs[row][1] = df1['score_dif'][row]\n",
    "        score_diffs[row][2] = 1\n",
    "\n",
    "#   creating a list of all the auc scores\n",
    "    for row in range(rows):\n",
    "        auc_score = auc(score_diffs[row], test_scores[row])\n",
    "        auc_scores.append(auc_score)\n",
    "        \n",
    "#   getting the greatest auc score, and the index number of that row    \n",
    "    best_auc_score = max(auc_scores)\n",
    "    best_score_index = auc_scores.index(best_auc_score)\n",
    "    \n",
    "\n",
    "#   specifying what will be returned\n",
    "    return (str(model_type), df1['mean_test_score'][best_score_index], df1['score_dif'][best_score_index],\n",
    "            best_auc_score,df2['params'][best_score_index],best_score_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_scores_df(gs_obj):\n",
    "    \n",
    "    # Creates a dataframe from gs_obj.cv_results_ dictionary:\n",
    "    results_df = pd.DataFrame(gs_obj.cv_results_)\n",
    "\n",
    "    # adding new column:\n",
    "    results_df['score_dif'] = abs(results_df['mean_train_score'] - results_df['mean_test_score'])\n",
    "\n",
    "    # creates new dataframe with only 'train','test' scores, and their difference:\n",
    "    score_df = pd.DataFrame()\n",
    "    score_df = results_df.loc[:,['mean_train_score','mean_test_score','score_dif']]\n",
    "    \n",
    "    # returns .cv_results df, and df with mean train/test scores and their difference:\n",
    "    return results_df, score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_scores(gs_obj):\n",
    "    \n",
    "    # Mean training score\n",
    "    gs_training_score = np.mean(gs_obj.cv_results_['mean_train_score'])\n",
    "    \n",
    "    # Mean test score\n",
    "    gs_testing_score = np.mean(gs_obj.cv_results_['mean_test_score'])\n",
    "    \n",
    "    print(f\"Mean Training Score: {gs_training_score :.2%}\")\n",
    "    print(f\"Mean Test Score: {gs_testing_score :.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing dataset\n",
    "df = pd.read_csv('H1N1_Flu_Vaccines.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 26707 entries, 0 to 26706\n",
      "Data columns (total 38 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   respondent_id                26707 non-null  int64  \n",
      " 1   h1n1_concern                 26615 non-null  float64\n",
      " 2   h1n1_knowledge               26591 non-null  float64\n",
      " 3   behavioral_antiviral_meds    26636 non-null  float64\n",
      " 4   behavioral_avoidance         26499 non-null  float64\n",
      " 5   behavioral_face_mask         26688 non-null  float64\n",
      " 6   behavioral_wash_hands        26665 non-null  float64\n",
      " 7   behavioral_large_gatherings  26620 non-null  float64\n",
      " 8   behavioral_outside_home      26625 non-null  float64\n",
      " 9   behavioral_touch_face        26579 non-null  float64\n",
      " 10  doctor_recc_h1n1             24547 non-null  float64\n",
      " 11  doctor_recc_seasonal         24547 non-null  float64\n",
      " 12  chronic_med_condition        25736 non-null  float64\n",
      " 13  child_under_6_months         25887 non-null  float64\n",
      " 14  health_worker                25903 non-null  float64\n",
      " 15  health_insurance             14433 non-null  float64\n",
      " 16  opinion_h1n1_vacc_effective  26316 non-null  float64\n",
      " 17  opinion_h1n1_risk            26319 non-null  float64\n",
      " 18  opinion_h1n1_sick_from_vacc  26312 non-null  float64\n",
      " 19  opinion_seas_vacc_effective  26245 non-null  float64\n",
      " 20  opinion_seas_risk            26193 non-null  float64\n",
      " 21  opinion_seas_sick_from_vacc  26170 non-null  float64\n",
      " 22  age_group                    26707 non-null  object \n",
      " 23  education                    25300 non-null  object \n",
      " 24  race                         26707 non-null  object \n",
      " 25  sex                          26707 non-null  object \n",
      " 26  income_poverty               22284 non-null  object \n",
      " 27  marital_status               25299 non-null  object \n",
      " 28  rent_or_own                  24665 non-null  object \n",
      " 29  employment_status            25244 non-null  object \n",
      " 30  hhs_geo_region               26707 non-null  object \n",
      " 31  census_msa                   26707 non-null  object \n",
      " 32  household_adults             26458 non-null  float64\n",
      " 33  household_children           26458 non-null  float64\n",
      " 34  employment_industry          13377 non-null  object \n",
      " 35  employment_occupation        13237 non-null  object \n",
      " 36  h1n1_vaccine                 26707 non-null  int64  \n",
      " 37  seasonal_vaccine             26707 non-null  int64  \n",
      "dtypes: float64(23), int64(3), object(12)\n",
      "memory usage: 7.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>respondent_id</th>\n",
       "      <th>h1n1_concern</th>\n",
       "      <th>h1n1_knowledge</th>\n",
       "      <th>behavioral_antiviral_meds</th>\n",
       "      <th>behavioral_avoidance</th>\n",
       "      <th>behavioral_face_mask</th>\n",
       "      <th>behavioral_wash_hands</th>\n",
       "      <th>behavioral_large_gatherings</th>\n",
       "      <th>behavioral_outside_home</th>\n",
       "      <th>behavioral_touch_face</th>\n",
       "      <th>...</th>\n",
       "      <th>rent_or_own</th>\n",
       "      <th>employment_status</th>\n",
       "      <th>hhs_geo_region</th>\n",
       "      <th>census_msa</th>\n",
       "      <th>household_adults</th>\n",
       "      <th>household_children</th>\n",
       "      <th>employment_industry</th>\n",
       "      <th>employment_occupation</th>\n",
       "      <th>h1n1_vaccine</th>\n",
       "      <th>seasonal_vaccine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Own</td>\n",
       "      <td>Not in Labor Force</td>\n",
       "      <td>oxchjgsf</td>\n",
       "      <td>Non-MSA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Rent</td>\n",
       "      <td>Employed</td>\n",
       "      <td>bhuqouqj</td>\n",
       "      <td>MSA, Not Principle  City</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>pxcmvdjn</td>\n",
       "      <td>xgwztkwe</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Own</td>\n",
       "      <td>Employed</td>\n",
       "      <td>qufhixun</td>\n",
       "      <td>MSA, Not Principle  City</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>rucpziij</td>\n",
       "      <td>xtkaffoo</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Rent</td>\n",
       "      <td>Not in Labor Force</td>\n",
       "      <td>lrircsnp</td>\n",
       "      <td>MSA, Principle City</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Own</td>\n",
       "      <td>Employed</td>\n",
       "      <td>qufhixun</td>\n",
       "      <td>MSA, Not Principle  City</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>wxleyezf</td>\n",
       "      <td>emcorrxb</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   respondent_id  h1n1_concern  h1n1_knowledge  behavioral_antiviral_meds  \\\n",
       "0              0           1.0             0.0                        0.0   \n",
       "1              1           3.0             2.0                        0.0   \n",
       "2              2           1.0             1.0                        0.0   \n",
       "3              3           1.0             1.0                        0.0   \n",
       "4              4           2.0             1.0                        0.0   \n",
       "\n",
       "   behavioral_avoidance  behavioral_face_mask  behavioral_wash_hands  \\\n",
       "0                   0.0                   0.0                    0.0   \n",
       "1                   1.0                   0.0                    1.0   \n",
       "2                   1.0                   0.0                    0.0   \n",
       "3                   1.0                   0.0                    1.0   \n",
       "4                   1.0                   0.0                    1.0   \n",
       "\n",
       "   behavioral_large_gatherings  behavioral_outside_home  \\\n",
       "0                          0.0                      1.0   \n",
       "1                          0.0                      1.0   \n",
       "2                          0.0                      0.0   \n",
       "3                          1.0                      0.0   \n",
       "4                          1.0                      0.0   \n",
       "\n",
       "   behavioral_touch_face  ...  rent_or_own   employment_status  \\\n",
       "0                    1.0  ...          Own  Not in Labor Force   \n",
       "1                    1.0  ...         Rent            Employed   \n",
       "2                    0.0  ...          Own            Employed   \n",
       "3                    0.0  ...         Rent  Not in Labor Force   \n",
       "4                    1.0  ...          Own            Employed   \n",
       "\n",
       "   hhs_geo_region                census_msa  household_adults  \\\n",
       "0        oxchjgsf                   Non-MSA               0.0   \n",
       "1        bhuqouqj  MSA, Not Principle  City               0.0   \n",
       "2        qufhixun  MSA, Not Principle  City               2.0   \n",
       "3        lrircsnp       MSA, Principle City               0.0   \n",
       "4        qufhixun  MSA, Not Principle  City               1.0   \n",
       "\n",
       "   household_children  employment_industry  employment_occupation  \\\n",
       "0                 0.0                  NaN                    NaN   \n",
       "1                 0.0             pxcmvdjn               xgwztkwe   \n",
       "2                 0.0             rucpziij               xtkaffoo   \n",
       "3                 0.0                  NaN                    NaN   \n",
       "4                 0.0             wxleyezf               emcorrxb   \n",
       "\n",
       "   h1n1_vaccine  seasonal_vaccine  \n",
       "0             0                 0  \n",
       "1             0                 1  \n",
       "2             0                 0  \n",
       "3             0                 1  \n",
       "4             0                 0  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Counts\n",
      "0    21033\n",
      "1     5674\n",
      "Name: h1n1_vaccine, dtype: int64\n",
      "\n",
      "Percentages\n",
      "0    0.787546\n",
      "1    0.212454\n",
      "Name: h1n1_vaccine, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Raw Counts\")\n",
    "print(df[\"h1n1_vaccine\"].value_counts())\n",
    "print()\n",
    "print(\"Percentages\")\n",
    "print(df[\"h1n1_vaccine\"].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>A baseline model that always chose the majority class would have an accuracy of over 78%.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing the Data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping Features, Train-test-split, and Dealing with Missing Values: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#I will drop:\n",
    "# 'respondent_id' - since it is a unique identifier\n",
    "# 'employment_industry','employment_occupation','health_insurance' - about 50% or more records missing \n",
    "# 'seasonal_vaccine' - we will not account for this classification\n",
    "df_II = df.drop(['respondent_id','employment_industry','employment_occupation','health_insurance'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split df into X and y\n",
    "X = df_II.drop(\"h1n1_vaccine\", axis=1)\n",
    "y = df_II[\"h1n1_vaccine\"]\n",
    "\n",
    "# Perform train-test split with random_state=42 and stratify=y\n",
    "# stratify y to maintain uniform ratios of dependent variable y\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#impute values based on most common value in each column:\n",
    "X_train = X_train.apply(lambda x:x.fillna(x.value_counts().index[0]))\n",
    "X_test = X_test.apply(lambda x:x.fillna(x.value_counts().index[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>There is now no missing data in the training dataset.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# splitting dataframe between ordinals , categoricals, and nominals\n",
    "X_train_ord =  X_train.iloc[:,np.r_[0:2,14:22,24]]\n",
    "X_train_nom = X_train.iloc[:,30:32]\n",
    "ord_cols = X_train_ord.columns\n",
    "nom_cols = X_train_nom.columns\n",
    "cols_to_drop = ord_cols.append(nom_cols)\n",
    "X_train_cat = X_train.drop(cols_to_drop, axis=1)\n",
    "X_train_ord_index = X_train_ord.index\n",
    "X_train_cat_index = X_train_cat.index\n",
    "\n",
    "# I will convert all the columns in the dataset to string type, so I can then encode them:\n",
    "X_train_ord = X_train_ord.astype(str)\n",
    "X_train_cat = X_train_cat.astype(str)\n",
    "\n",
    "# creating a Encoder objects:\n",
    "enc = OrdinalEncoder()\n",
    "ohe = OneHotEncoder(categories=\"auto\", handle_unknown=\"ignore\", sparse=False)\n",
    "\n",
    "# fitting dataset to OneHotEncoder object:\n",
    "X_train_enc = enc.fit_transform(X_train_ord)\n",
    "X_train_ohe = ohe.fit_transform(X_train_cat)\n",
    "\n",
    "# creating an array with enc and ohe column names:\n",
    "enc_col_names = X_train_ord.columns\n",
    "ohe_col_names = ohe.get_feature_names(X_train_cat.columns)\n",
    "\n",
    "# Setting arrays back to dataframes\n",
    "X_train_enc_df = pd.DataFrame(X_train_enc, columns=enc_col_names,index=X_train_ord_index)\n",
    "X_train_ohe_df = pd.DataFrame(X_train_ohe, columns=ohe_col_names,index=X_train_cat_index)\n",
    "\n",
    "# putting the datframe back together:\n",
    "X_train_II_encoded = pd.concat([X_train_enc_df,X_train_ohe_df,X_train_nom],axis=1)\n",
    "X_train_II_encoded.head()\n",
    "\n",
    "# resampling with Smote *after some trial and error, I found 60/40 to be optimal:\n",
    "X_train_II_encoded_resampled, y_train_resampled = SMOTE().fit_resample(X_train_II_encoded, y_train)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Counts\n",
      "1    15775\n",
      "0    15775\n",
      "Name: h1n1_vaccine, dtype: int64\n",
      "\n",
      "Percentages\n",
      "1    0.5\n",
      "0    0.5\n",
      "Name: h1n1_vaccine, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Raw Counts\")\n",
    "print(y_train_resampled.value_counts())\n",
    "print()\n",
    "print(\"Percentages\")\n",
    "print(y_train_resampled.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>h1n1_concern</th>\n",
       "      <th>h1n1_knowledge</th>\n",
       "      <th>opinion_h1n1_vacc_effective</th>\n",
       "      <th>opinion_h1n1_risk</th>\n",
       "      <th>opinion_h1n1_sick_from_vacc</th>\n",
       "      <th>opinion_seas_vacc_effective</th>\n",
       "      <th>opinion_seas_risk</th>\n",
       "      <th>opinion_seas_sick_from_vacc</th>\n",
       "      <th>age_group</th>\n",
       "      <th>education</th>\n",
       "      <th>...</th>\n",
       "      <th>hhs_geo_region_mlyzmhmf</th>\n",
       "      <th>hhs_geo_region_oxchjgsf</th>\n",
       "      <th>hhs_geo_region_qufhixun</th>\n",
       "      <th>census_msa_MSA, Not Principle  City</th>\n",
       "      <th>census_msa_MSA, Principle City</th>\n",
       "      <th>census_msa_Non-MSA</th>\n",
       "      <th>seasonal_vaccine_0</th>\n",
       "      <th>seasonal_vaccine_1</th>\n",
       "      <th>household_adults</th>\n",
       "      <th>household_children</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12369</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17593</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2698</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13754</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7106</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       h1n1_concern  h1n1_knowledge  opinion_h1n1_vacc_effective  \\\n",
       "12369           3.0             1.0                          3.0   \n",
       "17593           3.0             2.0                          4.0   \n",
       "2698            3.0             1.0                          3.0   \n",
       "13754           2.0             2.0                          3.0   \n",
       "7106            2.0             1.0                          2.0   \n",
       "\n",
       "       opinion_h1n1_risk  opinion_h1n1_sick_from_vacc  \\\n",
       "12369                0.0                          3.0   \n",
       "17593                1.0                          0.0   \n",
       "2698                 0.0                          1.0   \n",
       "13754                1.0                          1.0   \n",
       "7106                 3.0                          1.0   \n",
       "\n",
       "       opinion_seas_vacc_effective  opinion_seas_risk  \\\n",
       "12369                          3.0                0.0   \n",
       "17593                          4.0                1.0   \n",
       "2698                           4.0                0.0   \n",
       "13754                          3.0                1.0   \n",
       "7106                           0.0                3.0   \n",
       "\n",
       "       opinion_seas_sick_from_vacc  age_group  education  ...  \\\n",
       "12369                          1.0        3.0        0.0  ...   \n",
       "17593                          0.0        1.0        2.0  ...   \n",
       "2698                           0.0        0.0        3.0  ...   \n",
       "13754                          1.0        3.0        2.0  ...   \n",
       "7106                           1.0        0.0        3.0  ...   \n",
       "\n",
       "       hhs_geo_region_mlyzmhmf  hhs_geo_region_oxchjgsf  \\\n",
       "12369                      0.0                      0.0   \n",
       "17593                      1.0                      0.0   \n",
       "2698                       0.0                      0.0   \n",
       "13754                      0.0                      0.0   \n",
       "7106                       0.0                      0.0   \n",
       "\n",
       "       hhs_geo_region_qufhixun  census_msa_MSA, Not Principle  City  \\\n",
       "12369                      0.0                                  0.0   \n",
       "17593                      0.0                                  1.0   \n",
       "2698                       0.0                                  0.0   \n",
       "13754                      0.0                                  0.0   \n",
       "7106                       0.0                                  1.0   \n",
       "\n",
       "       census_msa_MSA, Principle City  census_msa_Non-MSA  seasonal_vaccine_0  \\\n",
       "12369                             0.0                 1.0                 0.0   \n",
       "17593                             0.0                 0.0                 0.0   \n",
       "2698                              1.0                 0.0                 1.0   \n",
       "13754                             1.0                 0.0                 1.0   \n",
       "7106                              0.0                 0.0                 0.0   \n",
       "\n",
       "       seasonal_vaccine_1  household_adults  household_children  \n",
       "12369                 1.0               0.0                 0.0  \n",
       "17593                 1.0               1.0                 2.0  \n",
       "2698                  0.0               1.0                 2.0  \n",
       "13754                 0.0               1.0                 0.0  \n",
       "7106                  1.0               3.0                 3.0  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# splitting dataframe between ordinals and categoricals\n",
    "X_test_ord =  X_test.iloc[:,np.r_[0:2,14:22,24]]\n",
    "X_test_nom = X_test.iloc[:,30:32]\n",
    "ord_cols = X_test_ord.columns\n",
    "nom_cols = X_test_nom.columns\n",
    "cols_to_drop = ord_cols.append(nom_cols)\n",
    "X_test_cat = X_test.drop(cols_to_drop, axis=1)\n",
    "\n",
    "# create index arrays to use when I recreate the dataframe\n",
    "X_test_ord_index = X_test_ord.index\n",
    "X_test_cat_index = X_test_cat.index\n",
    "\n",
    "# I will convert all the columns in the dataset to string type, so I can then encode them:\n",
    "X_test_ord = X_test_ord.astype(str)\n",
    "X_test_cat = X_test_cat.astype(str)\n",
    "\n",
    "# Setting arrays back to dataframes\n",
    "X_test_enc_df = pd.DataFrame(enc.transform(X_test_ord), columns=enc_col_names,index=X_test_ord_index)\n",
    "X_test_ohe_df = pd.DataFrame(ohe.transform(X_test_cat), columns=ohe_col_names,index=X_test_cat_index)\n",
    "\n",
    "#putting the datframe back together:\n",
    "X_test_II_encoded = pd.concat([X_test_enc_df,X_test_ohe_df,X_test_nom],axis=1)\n",
    "X_test_II_encoded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification models:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Nearest Neighbors (KNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K Nearest Neighbors Baseline Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Cross Validation Score: 96.42%\n"
     ]
    }
   ],
   "source": [
    "# Creating K nearest neighbor classifier object \n",
    "knn = KNeighborsClassifier(n_jobs = -1)\n",
    "\n",
    "# using 2-split cross-validation to score the classification:\n",
    "knn_cv_score = cross_val_score(knn, X_train_II_encoded_resampled, y_train_resampled, scoring= 'recall', cv=2)\n",
    "\n",
    "# return the mean of the 2 f1 scores:\n",
    "mean_knn_cv_score = np.mean(knn_cv_score)\n",
    "print(f\"Mean Cross Validation Score: {mean_knn_cv_score :.2%}\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The model did significantly better than we would expect from random guessing (~60% better),\n",
    "and slightly better than we would expect if we simply choose the majority label (~79%)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using GridSearchCV to create additional KNN models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid:\n",
    "\n",
    "knn_param_grid = {\n",
    "    'n_neighbors': [5,12,20],\n",
    "    'metric'     : ['minkowski'],\n",
    "    'p'          : [1,2,3,4]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate GridSearchCV object:\n",
    "knn_grid_search = GridSearchCV(knn, knn_param_grid, cv=2, scoring='recall',return_train_score=True, n_jobs = -1)\n",
    "\n",
    "# fit to the data:\n",
    "knn_grid_search.fit(X_train_II_encoded_resampled, y_train_resampled);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Training Score: 92.65%\n",
      "Mean Test Score: 91.30%\n"
     ]
    }
   ],
   "source": [
    "print_scores(knn_grid_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>score_dif</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.926469</td>\n",
       "      <td>0.912989</td>\n",
       "      <td>0.013480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.047556</td>\n",
       "      <td>0.057225</td>\n",
       "      <td>0.012765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.822312</td>\n",
       "      <td>0.791693</td>\n",
       "      <td>0.003042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.922375</td>\n",
       "      <td>0.908556</td>\n",
       "      <td>0.006225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.934800</td>\n",
       "      <td>0.920825</td>\n",
       "      <td>0.006877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.951551</td>\n",
       "      <td>0.941949</td>\n",
       "      <td>0.014737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.977685</td>\n",
       "      <td>0.973819</td>\n",
       "      <td>0.037718</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       mean_train_score  mean_test_score  score_dif\n",
       "count         12.000000        12.000000  12.000000\n",
       "mean           0.926469         0.912989   0.013480\n",
       "std            0.047556         0.057225   0.012765\n",
       "min            0.822312         0.791693   0.003042\n",
       "25%            0.922375         0.908556   0.006225\n",
       "50%            0.934800         0.920825   0.006877\n",
       "75%            0.951551         0.941949   0.014737\n",
       "max            0.977685         0.973819   0.037718"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_results_df, knn_score_df =  create_model_scores_df(knn_grid_search)\n",
    "knn_score_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Baseline Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Cross Validation Score: 80.08%\n"
     ]
    }
   ],
   "source": [
    "# Creating decision tree classifier object\n",
    "dec_tree = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# using 2-split cross-validation to score the classification:\n",
    "dec_tree_cv_score = cross_val_score(dec_tree, X_train_II_encoded_resampled, y_train_resampled,\n",
    "                                    cv=2,scoring='recall')\n",
    "\n",
    "# return the mean of the 2 f1 scores:\n",
    "mean_dec_tree_cv_score = np.mean(dec_tree_cv_score)\n",
    "print(f\"Mean Cross Validation Score: {mean_dec_tree_cv_score :.2%}\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The model did significantly better than we would expect from random guessing (~50% better),\n",
    "but slightly worse than we would expect if we simply choose the majority label (~79%)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using GridSearchCV to create additional Decision Tree models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid:\n",
    "\n",
    "dec_tree_param_grid = {\n",
    "    'criterion'        : ['gini', 'entropy'],\n",
    "    'max_depth'        : [None,5,6, 7, 8],\n",
    "    'min_samples_split': [2,3,5],\n",
    "    'min_samples_leaf' : [1, 2, 3, 4, 5, 6],\n",
    "    'class_weight'     : [None, 'balanced']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate GridSearchCV object:\n",
    "dec_tree_grid_search = GridSearchCV(dec_tree, dec_tree_param_grid, cv=2, return_train_score=True, \n",
    "                                    scoring='recall', n_jobs = -1)\n",
    "\n",
    "# fit to the data:\n",
    "dec_tree_grid_search.fit(X_train_II_encoded_resampled, y_train_resampled);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Training Score: 90.09%\n",
      "Mean Test Score: 83.84%\n"
     ]
    }
   ],
   "source": [
    "print_scores(dec_tree_grid_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>score_dif</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>360.000000</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>360.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.900893</td>\n",
       "      <td>0.838412</td>\n",
       "      <td>0.062481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.037661</td>\n",
       "      <td>0.030361</td>\n",
       "      <td>0.053070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.850777</td>\n",
       "      <td>0.780718</td>\n",
       "      <td>0.023716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.878953</td>\n",
       "      <td>0.823384</td>\n",
       "      <td>0.030056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.897844</td>\n",
       "      <td>0.837046</td>\n",
       "      <td>0.043772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.915734</td>\n",
       "      <td>0.868283</td>\n",
       "      <td>0.047673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.887793</td>\n",
       "      <td>0.199188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       mean_train_score  mean_test_score   score_dif\n",
       "count        360.000000       360.000000  360.000000\n",
       "mean           0.900893         0.838412    0.062481\n",
       "std            0.037661         0.030361    0.053070\n",
       "min            0.850777         0.780718    0.023716\n",
       "25%            0.878953         0.823384    0.030056\n",
       "50%            0.897844         0.837046    0.043772\n",
       "75%            0.915734         0.868283    0.047673\n",
       "max            1.000000         0.887793    0.199188"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_tree_results_df, dec_tree_score_df =  create_model_scores_df(dec_tree_grid_search)\n",
    "dec_tree_score_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Baseline Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Cross Validation Score: 83.35%\n"
     ]
    }
   ],
   "source": [
    "# creating random forest classifier object:\n",
    "forest = RandomForestClassifier(n_jobs = -1,random_state=42)\n",
    "\n",
    "# using 2-split cross-validation to score the classification:\n",
    "forest_cv_score = cross_val_score(forest, X_train_II_encoded_resampled, y_train_resampled, cv=2,scoring='recall')\n",
    "\n",
    "# return the mean of the 2 f1 scores:\n",
    "mean_forest_cv_score = np.mean(forest_cv_score)\n",
    "print(f\"Mean Cross Validation Score: {mean_forest_cv_score :.2%}\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The model did significantly better than we would expect from random guessing (~66% better),\n",
    "but slightly worse than we would expect if we simply choose the majority label (~79%)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using GridSearchCV to create additional Random Forests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid:\n",
    "\n",
    "forest_param_grid = {\n",
    "              'criterion'        : ['gini', 'entropy'],\n",
    "              'max_depth'        : [None, 4, 5, 6, 8],\n",
    "              'min_samples_split': [2, 3, 4, 6],\n",
    "              'max_features'     : [15, 20, 28, 32, 'auto'],\n",
    "             'class_weight'      : [None, 'balanced'],\n",
    "              'n_estimators'     : [100, 150]\n",
    "         \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate GridSearchCV object:\n",
    "forest_grid_search = GridSearchCV(forest, forest_param_grid, cv=2, return_train_score=True,\n",
    "                                  scoring='recall', n_jobs = -1)\n",
    "\n",
    "# Fit to the data:\n",
    "forest_grid_search.fit(X_train_II_encoded_resampled, y_train_resampled);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_weight': 'balanced',\n",
       " 'criterion': 'entropy',\n",
       " 'max_depth': 4,\n",
       " 'max_features': 32,\n",
       " 'min_samples_split': 2,\n",
       " 'n_estimators': 100}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Training Score: 91.51%\n",
      "Mean Test Score: 85.64%\n"
     ]
    }
   ],
   "source": [
    "print_scores(forest_grid_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>score_dif</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>800.000000</td>\n",
       "      <td>800.000000</td>\n",
       "      <td>800.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.915060</td>\n",
       "      <td>0.856365</td>\n",
       "      <td>0.058695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.042187</td>\n",
       "      <td>0.019128</td>\n",
       "      <td>0.057296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.863579</td>\n",
       "      <td>0.817168</td>\n",
       "      <td>0.001141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.889855</td>\n",
       "      <td>0.844418</td>\n",
       "      <td>0.022823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.898064</td>\n",
       "      <td>0.859677</td>\n",
       "      <td>0.032839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.917588</td>\n",
       "      <td>0.865478</td>\n",
       "      <td>0.057136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.896986</td>\n",
       "      <td>0.182769</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       mean_train_score  mean_test_score   score_dif\n",
       "count        800.000000       800.000000  800.000000\n",
       "mean           0.915060         0.856365    0.058695\n",
       "std            0.042187         0.019128    0.057296\n",
       "min            0.863579         0.817168    0.001141\n",
       "25%            0.889855         0.844418    0.022823\n",
       "50%            0.898064         0.859677    0.032839\n",
       "75%            0.917588         0.865478    0.057136\n",
       "max            1.000000         0.896986    0.182769"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_results_df, forest_score_df =  create_model_scores_df(forest_grid_search)\n",
    "forest_score_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating new dataframes with 2 column names modified so they work with XGBoost:\n",
    "\n",
    "X_train_III_encoded = X_train_II_encoded_resampled.rename(columns={'education_< 12 Years': 'education less than 12 Years', \n",
    "                                                         'income_poverty_<= $75,000, Above Poverty':\n",
    "                                                         'income_poverty less than or = to $75000_Above Poverty'})\n",
    "X_test_III_encoded = X_test_II_encoded.rename(columns={'education_< 12 Years': 'education less than 12 Years', \n",
    "                                                         'income_poverty_<= $75,000, Above Poverty':\n",
    "                                                         'income_poverty less than or = to $75000_Above Poverty'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost Baseline Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Cross Validation Score: 73.01%\n"
     ]
    }
   ],
   "source": [
    "# Creating XGBoost classifier object:\n",
    "xgboost_clf = XGBClassifier(random_state=42, n_jobs = -1)\n",
    "\n",
    "# using 2-split cross-validation to score the classification:\n",
    "xgboost_clf_cv_score = cross_val_score(xgboost_clf, X_train_II_encoded_resampled, y_train_resampled,\n",
    "                                       cv=2, scoring='recall')\n",
    "\n",
    "# return the mean of the 2 f1 scores:\n",
    "mean_xgboost_clf_cv_score = np.mean(xgboost_clf_cv_score)\n",
    "print(f\"Mean Cross Validation Score: {mean_xgboost_clf_cv_score :.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using GridSearchCV to create additional XGBoost Classifiers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Define the parameter grid:\n",
    "\n",
    "xgboost_param_grid = {\n",
    "    'learning_rate': [.08, .1, .3],\n",
    "    'max_depth': [4, 5, 6 ],\n",
    "    'min_child_weight': [1, 2, 3],\n",
    "    'subsample': [0.65, 1],\n",
    "    'min_split_loss' : [0, .5],\n",
    "    'n_estimators' : [100, 160],\n",
    "    'reg_alpha':[0, .5],\n",
    "    'scale_pos_weight' : [1, 3.0]\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate GridSearchCV object:\n",
    "xgboost_clf_grid_search = GridSearchCV(xgboost_clf, xgboost_param_grid, cv=2, return_train_score=True,\n",
    "                                  scoring='recall', n_jobs = -1)\n",
    "\n",
    "# Fit to the data\n",
    "xgboost_clf_grid_search.fit(X_train_II_encoded_resampled, y_train_resampled);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Training Score: 95.92%\n",
      "Mean Test Score: 75.14%\n"
     ]
    }
   ],
   "source": [
    "print_scores(xgboost_clf_grid_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>score_dif</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>864.000000</td>\n",
       "      <td>864.000000</td>\n",
       "      <td>864.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.959206</td>\n",
       "      <td>0.751415</td>\n",
       "      <td>0.207790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.023198</td>\n",
       "      <td>0.031409</td>\n",
       "      <td>0.036813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.918474</td>\n",
       "      <td>0.729745</td>\n",
       "      <td>0.110815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.935273</td>\n",
       "      <td>0.730696</td>\n",
       "      <td>0.184449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.970204</td>\n",
       "      <td>0.735387</td>\n",
       "      <td>0.209712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.977510</td>\n",
       "      <td>0.759636</td>\n",
       "      <td>0.236782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.998098</td>\n",
       "      <td>0.858945</td>\n",
       "      <td>0.267656</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       mean_train_score  mean_test_score   score_dif\n",
       "count        864.000000       864.000000  864.000000\n",
       "mean           0.959206         0.751415    0.207790\n",
       "std            0.023198         0.031409    0.036813\n",
       "min            0.918474         0.729745    0.110815\n",
       "25%            0.935273         0.730696    0.184449\n",
       "50%            0.970204         0.735387    0.209712\n",
       "75%            0.977510         0.759636    0.236782\n",
       "max            0.998098         0.858945    0.267656"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgboost_results_df, xgboost_score_df =  create_model_scores_df(xgboost_clf_grid_search)\n",
    "xgboost_score_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choosing the Best Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model type</th>\n",
       "      <th>best test score(f1)</th>\n",
       "      <th>best score difference</th>\n",
       "      <th>best train-test combination score(auc)</th>\n",
       "      <th>best parameters</th>\n",
       "      <th>best dataframe row</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>knn</td>\n",
       "      <td>0.973819</td>\n",
       "      <td>0.003042</td>\n",
       "      <td>0.985388</td>\n",
       "      <td>{'metric': 'minkowski', 'n_neighbors': 5, 'p': 3}</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>decsion tree</td>\n",
       "      <td>0.887793</td>\n",
       "      <td>0.025359</td>\n",
       "      <td>0.931217</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'gini', 'max_depth': 6, 'min_samples_leaf': 1, 'min_samples_split': 2}</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>random forest</td>\n",
       "      <td>0.896986</td>\n",
       "      <td>0.008305</td>\n",
       "      <td>0.944340</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 4, 'max_features': 32, 'min_samples_split': 2, 'n_estimators': 100}</td>\n",
       "      <td>664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>0.858945</td>\n",
       "      <td>0.110815</td>\n",
       "      <td>0.874065</td>\n",
       "      <td>{'learning_rate': 0.08, 'max_depth': 4, 'min_child_weight': 2, 'min_split_loss': 0.5, 'n_estimators': 100, 'reg_alpha': 0.5, 'scale_pos_weight': 3.0, 'subsample': 1}</td>\n",
       "      <td>343</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      model type  best test score(f1)  best score difference  \\\n",
       "0            knn             0.973819               0.003042   \n",
       "1   decsion tree             0.887793               0.025359   \n",
       "2  random forest             0.896986               0.008305   \n",
       "3        xgboost             0.858945               0.110815   \n",
       "\n",
       "   best train-test combination score(auc)  \\\n",
       "0                                0.985388   \n",
       "1                                0.931217   \n",
       "2                                0.944340   \n",
       "3                                0.874065   \n",
       "\n",
       "                                                                                                                                                         best parameters  \\\n",
       "0                                                                                                                      {'metric': 'minkowski', 'n_neighbors': 5, 'p': 3}   \n",
       "1                                                             {'class_weight': None, 'criterion': 'gini', 'max_depth': 6, 'min_samples_leaf': 1, 'min_samples_split': 2}   \n",
       "2                                  {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 4, 'max_features': 32, 'min_samples_split': 2, 'n_estimators': 100}   \n",
       "3  {'learning_rate': 0.08, 'max_depth': 4, 'min_child_weight': 2, 'min_split_loss': 0.5, 'n_estimators': 100, 'reg_alpha': 0.5, 'scale_pos_weight': 3.0, 'subsample': 1}   \n",
       "\n",
       "   best dataframe row  \n",
       "0                   2  \n",
       "1                  36  \n",
       "2                 664  \n",
       "3                 343  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating a dataframe to compare models\n",
    "\n",
    "#creating list of arguments for the 'best_model' function\n",
    "best_model_args = [['knn', knn_score_df, knn_results_df],\n",
    "                   ['decsion tree', dec_tree_score_df, dec_tree_results_df],\n",
    "                   ['random forest', forest_score_df, forest_results_df],\n",
    "                   ['xgboost', xgboost_score_df, xgboost_results_df]]\n",
    "\n",
    "\n",
    "# loop counter representing the 4 sets of arguments for the 'best_model' function\n",
    "counter = 0\n",
    "# this list will hold the stats for each model\n",
    "model_stats_list = []\n",
    "# column names used to create the dataframe\n",
    "model_stats_df_cols = ['model type','best test score(f1)','best score difference',\n",
    "                      'best train-test combination score(auc)','best parameters',\n",
    "                      'best dataframe row']\n",
    "\n",
    "# loop used to populate 'model_stats_list'\n",
    "while counter <4:\n",
    "    args = best_model_args[counter]\n",
    "    model_stats = best_model(args[0],args[1],args[2])\n",
    "    model_stats_list.append(model_stats)\n",
    "    counter+=1\n",
    "\n",
    "# creating dataframe from the 'model_stats_list'\n",
    "model_stats_df = pd.DataFrame(model_stats_list, columns=model_stats_df_cols)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "model_stats_df   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best model, based on the auc metric (0.921018) is random Forest.\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recreating the  the Best Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8527131782945736"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating K nearest neighbor classifier object: \n",
    "best_knn = KNeighborsClassifier(metric = 'minkowski', n_neighbors = 5, p = 4, n_jobs = -1)\n",
    "\n",
    "\n",
    "# Fit data to the K nearest neighbor classifier object: \n",
    "best_knn.fit(X_train_II_encoded_resampled, y_train_resampled)\n",
    "best_knn_preds = best_knn.predict(X_test_II_encoded)\n",
    "\n",
    "#Returns the f1 score on the given test data and labels:\n",
    "knn_recall_score = recall_score(y_test, best_knn_preds)\n",
    "knn_recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7914023960535589"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating random forest classifier object:\n",
    "best_forest = RandomForestClassifier(class_weight = 'balanced', criterion = 'entropy', max_depth = 4,\n",
    "                                     max_features = 28, min_samples_split = 2, n_estimators = 150,\n",
    "                                     n_jobs = -1,random_state=42)\n",
    "# Fit data to the K nearest neighbor classifier object: \n",
    "best_forest.fit(X_train_II_encoded_resampled, y_train_resampled)\n",
    "best_forest_preds = best_forest.predict(X_test_II_encoded)\n",
    "\n",
    "#Returns the f1 score on the given test data and labels:\n",
    "forest_recall_score = recall_score(y_test, best_forest_preds)\n",
    "forest_recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize your confusion matrix\n",
    "plot_confusion_matrix(best_knn, X_test_II_encoded, y_test,\n",
    "                     cmap=plt.cm.Blues)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding best threshold to optimize Recall score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7374787263329198"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict probabilities\n",
    "best_knn_pred_probs = best_knn.predict_proba(X_test_II_encoded)\n",
    "# keep probabilities for the positive outcome only\n",
    "best_knn_pred_probs = best_knn_pred_probs[:, 1]\n",
    "# calculate scores\n",
    "ns_auc = roc_auc_score(y_test, best_knn_pred_probs)\n",
    "ns_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test, best_knn_pred_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating 'prc_arr' 2d array, by appending precison', 'recall', 'thresholds':\n",
    "n = 0\n",
    "roc_auc_arr = []\n",
    "while n < len (thresholds):\n",
    "    roc_auc_return = []\n",
    "    roc_auc_return.append(fpr[n])\n",
    "    roc_auc_return.append(tpr[n])\n",
    "    roc_auc_return.append(thresholds[n])\n",
    "    roc_auc_arr.append(roc_auc_return)\n",
    "    n+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fpr</th>\n",
       "      <th>tpr</th>\n",
       "      <th>thresholds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.813427</td>\n",
       "      <td>0.957012</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.677634</td>\n",
       "      <td>0.919662</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.522632</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.362115</td>\n",
       "      <td>0.747005</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.185622</td>\n",
       "      <td>0.529246</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        fpr       tpr  thresholds\n",
       "6  1.000000  1.000000         0.0\n",
       "5  0.813427  0.957012         0.2\n",
       "4  0.677634  0.919662         0.4\n",
       "3  0.522632  0.852713         0.6\n",
       "2  0.362115  0.747005         0.8\n",
       "1  0.185622  0.529246         1.0\n",
       "0  0.000000  0.000000         2.0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating column names list:\n",
    "roc_auc_df_col_names = ['fpr', 'tpr', 'thresholds']\n",
    "\n",
    "# converting 'prc_arr' to a dataframe:\n",
    "roc_auc_df = pd.DataFrame(roc_auc_arr, columns=roc_auc_df_col_names)\n",
    "\n",
    "# creating a new column that calculates the f-score:\n",
    "#f_scores_df['f_score'] = ((2 * f_scores_df['precision'] * f_scores_df['recall']) /\n",
    "                         #(f_scores_df['precision'] + f_scores_df['recall']))\n",
    "\n",
    "# sort descending by f_score:\n",
    "roc_auc_df = roc_auc_df.sort_values(by='tpr', ascending=False)\n",
    "roc_auc_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Based on an optimal threshold of 0.570373 our final f1 score is 0.645055<b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain most important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_knn_ftrs = KNeighborsClassifier(metric = 'minkowski', n_neighbors = 5, p = 4, n_jobs = -1)\n",
    "best_knn_df = X_train_II_encoded_resampled.copy()\n",
    "X_test_II_temp = X_test_II_encoded.copy()\n",
    "temp_knn_scores = []\n",
    "temp_col_names = []\n",
    "ftr_dropped = []\n",
    "score_after_drop = []\n",
    "ftr_counter = 64\n",
    "main_counter = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter:  63 Current Time : 11:51:58\n",
      "Counter:  62 Current Time : 11:56:52\n",
      "Counter:  61 Current Time : 12:01:24\n",
      "Counter:  60 Current Time : 12:05:13\n",
      "Counter:  59 Current Time : 12:09:27\n",
      "Counter:  58 Current Time : 12:14:57\n",
      "Counter:  57 Current Time : 12:19:48\n",
      "Counter:  56 Current Time : 12:23:47\n",
      "Counter:  55 Current Time : 12:27:31\n",
      "Counter:  54 Current Time : 12:31:07\n",
      "Counter:  53 Current Time : 12:34:36\n",
      "Counter:  52 Current Time : 12:37:56\n",
      "Counter:  51 Current Time : 12:41:10\n",
      "Counter:  50 Current Time : 12:44:18\n",
      "Counter:  49 Current Time : 12:47:19\n",
      "Counter:  48 Current Time : 12:50:11\n",
      "Counter:  47 Current Time : 12:52:57\n",
      "Counter:  46 Current Time : 12:55:37\n",
      "Counter:  45 Current Time : 12:58:11\n",
      "Counter:  44 Current Time : 13:00:39\n",
      "Counter:  43 Current Time : 13:03:01\n",
      "Counter:  42 Current Time : 13:05:17\n",
      "Counter:  41 Current Time : 13:07:28\n",
      "Counter:  40 Current Time : 13:09:31\n",
      "Counter:  39 Current Time : 13:11:29\n",
      "Counter:  38 Current Time : 13:13:22\n",
      "Counter:  37 Current Time : 13:15:09\n",
      "Counter:  36 Current Time : 13:16:51\n",
      "Counter:  35 Current Time : 13:18:27\n",
      "Counter:  34 Current Time : 13:19:57\n",
      "Counter:  33 Current Time : 13:21:22\n",
      "Counter:  32 Current Time : 13:22:42\n",
      "Counter:  31 Current Time : 13:23:59\n",
      "Counter:  30 Current Time : 13:25:11\n",
      "Counter:  29 Current Time : 13:26:20\n",
      "Counter:  28 Current Time : 13:27:24\n",
      "Counter:  27 Current Time : 13:28:23\n",
      "Counter:  26 Current Time : 13:29:18\n",
      "Counter:  25 Current Time : 13:30:09\n",
      "Counter:  24 Current Time : 13:30:54\n",
      "Counter:  23 Current Time : 13:31:34\n",
      "Counter:  22 Current Time : 13:32:09\n",
      "Counter:  21 Current Time : 13:32:41\n",
      "Counter:  20 Current Time : 13:33:11\n",
      "Counter:  19 Current Time : 13:33:37\n",
      "Counter:  18 Current Time : 13:34:01\n",
      "Counter:  17 Current Time : 13:34:21\n",
      "Counter:  16 Current Time : 13:34:39\n",
      "Counter:  15 Current Time : 13:34:54\n",
      "Counter:  14 Current Time : 13:35:06\n",
      "Counter:  13 Current Time : 13:35:16\n",
      "Counter:  12 Current Time : 13:35:25\n",
      "Counter:  11 Current Time : 13:35:33\n",
      "Counter:  10 Current Time : 13:35:39\n",
      "Counter:  9 Current Time : 13:35:44\n",
      "Counter:  8 Current Time : 13:35:48\n",
      "Counter:  7 Current Time : 13:35:51\n",
      "Counter:  6 Current Time : 13:35:54\n",
      "Counter:  5 Current Time : 13:35:56\n",
      "Counter:  4 Current Time : 13:35:57\n",
      "Counter:  3 Current Time : 13:35:59\n",
      "Counter:  2 Current Time : 13:36:00\n",
      "Counter:  1 Current Time : 13:36:02\n"
     ]
    }
   ],
   "source": [
    "while main_counter >1:\n",
    "    while ftr_counter > 0:\n",
    "    \n",
    "    \n",
    "        temp_knn_df = best_knn_df\n",
    "        best_knn_cols = best_knn_df.columns\n",
    "        col_to_drop = best_knn_cols[ftr_counter]\n",
    "        temp_knn_df = best_knn_df.drop([col_to_drop], axis=1)\n",
    "    \n",
    "  \n",
    "      # Fit data to the K nearest neighbor classifier object: \n",
    "        best_knn_ftrs.fit(temp_knn_df, y_train_resampled)\n",
    "        best_knn_ftrs_preds = best_knn_ftrs.predict(X_test_II_temp.drop([col_to_drop], axis=1))\n",
    "    \n",
    "        #Returns the f1 score on the given test data and labels:\n",
    "        knn_ftrs_recall_score = recall_score(y_test, best_knn_ftrs_preds)\n",
    "        temp_col_names.append(col_to_drop)\n",
    "        temp_knn_scores.append(knn_ftrs_recall_score)\n",
    "    \n",
    "        ftr_counter -=1\n",
    "    \n",
    "    \n",
    "    #temp_knn_scores\n",
    "    max_score_idx = temp_knn_scores.index(max(temp_knn_scores))\n",
    "    max_score_after_drop = max(temp_knn_scores)\n",
    "    ftr_to_drop = temp_col_names[max_score_idx]\n",
    "    \n",
    "    # adding permanently dropped features to list:\n",
    "    ftr_dropped.append(ftr_to_drop)\n",
    "    \n",
    "    # adding running score after drop list:\n",
    "    score_after_drop.append(max_score_after_drop)\n",
    "    \n",
    "    \n",
    "    best_knn_df = best_knn_df.drop([ftr_to_drop], axis=1)\n",
    "    X_test_II_temp = X_test_II_temp.drop([ftr_to_drop], axis=1)\n",
    "    temp_knn_scores = []\n",
    "    temp_col_names = []\n",
    "    ftr_counter = len(best_knn_df.columns) -1   \n",
    "    main_counter -=1 \n",
    "    now = datetime.now()\n",
    "    current_time = now.strftime(\"%H:%M:%S\")\n",
    "    print(\"Counter: \", main_counter, \"Current Time :\", current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Time = 11:46:08\n"
     ]
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "current_time = now.strftime(\"%H:%M:%S\")\n",
    "print(\"Current Time =\", current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_jobs=-1, p=4)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_mini = X_train_II_encoded_resampled[['opinion_h1n1_vacc_effective','opinion_h1n1_sick_from_vacc']]\n",
    "X_test_mini = X_test_II_encoded[['opinion_h1n1_vacc_effective','opinion_h1n1_sick_from_vacc']]\n",
    "knn_mini = KNeighborsClassifier(metric = 'minkowski', n_neighbors = 5, p = 4, n_jobs = -1)\n",
    "knn_mini.fit(X_train_mini,y_train_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06694855532064835"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_mini_preds = knn_mini.predict(X_test_mini)\n",
    "knn_mini_recall_score = recall_score(y_test, knn_mini_preds)\n",
    "knn_mini_recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8527131782945736"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating K nearest neighbor classifier object: \n",
    "best_knn = KNeighborsClassifier(metric = 'minkowski', n_neighbors = 5, p = 4, n_jobs = -1)\n",
    "\n",
    "\n",
    "# Fit data to the K nearest neighbor classifier object: \n",
    "best_knn.fit(X_train_II_encoded_resampled, y_train_resampled)\n",
    "best_knn_preds = best_knn.predict(X_test_II_encoded)\n",
    "\n",
    "#Returns the f1 score on the given test data and labels:\n",
    "knn_recall_score = recall_score(y_test, best_knn_preds)\n",
    "knn_recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating K nearest neighbor classifier object: \n",
    "best_knn = KNeighborsClassifier(metric = 'minkowski', n_neighbors = 5, p = 4, n_jobs = -1)\n",
    "\n",
    "\n",
    "# Fit data to the K nearest neighbor classifier object: \n",
    "best_knn.fit(X_train_II_encoded_resampled, y_train_resampled)\n",
    "best_knn_preds = best_knn.predict(X_test_II_encoded)\n",
    "\n",
    "#Returns the f1 score on the given test data and labels:\n",
    "knn_recall_score = recall_score(y_test, best_knn_preds)\n",
    "knn_recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'KNeighborsClassifier' object has no attribute 'feature_importances_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-148f2fa4a19d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# creating a 'ftr_importance' array:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mftr_importance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_knn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# creating a 'ftr_names' array:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mftr_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_II_encoded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KNeighborsClassifier' object has no attribute 'feature_importances_'"
     ]
    }
   ],
   "source": [
    "# creating a 'ftr_importance' array:\n",
    "ftr_importance = np.array(best_knn.feature_importances_)\n",
    "\n",
    "# creating a 'ftr_names' array:\n",
    "ftr_names = np.array(X_train_II_encoded.columns)\n",
    "\n",
    "# putting the two arrays together to create a 2d dataframe:\n",
    "ftr_importance_arr = np.vstack((ftr_names, ftr_importance)).T\n",
    "\n",
    "# creating column names list for dataframe:\n",
    "col_names = ['ftr_name', 'ftr_importance']\n",
    "\n",
    "# converting 'ftr_importance_arr' into a dataframe and sorting by feature importance:\n",
    "ftr_importance_df = pd.DataFrame(ftr_importance_arr, columns=col_names).sort_values(\n",
    "    by='ftr_importance')\n",
    "ftr_importance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an abridged dataframe that contributes at least 0.0001 towards 'gini' reduction:\n",
    "ftr_importance_df_II = ftr_importance_df.loc[ftr_importance_df['ftr_importance']>=0.0001]\n",
    "ftr_importance_df_II = ftr_importance_df_II.reset_index(drop=True)\n",
    "ftr_importance_df_II['ftr_importance'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importances(model):\n",
    "    n_features = model.shape[0]\n",
    "    plt.figure(figsize=(12,12))\n",
    "    plt.barh(range(n_features), model['ftr_importance'], align='center') \n",
    "    plt.yticks(np.arange(n_features), model['ftr_name']) \n",
    "    plt.xlabel('Feature importance')\n",
    "    plt.ylabel('Feature')\n",
    "\n",
    "plot_feature_importances(ftr_importance_df_II)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
